# This workflow is a reusable one called by other workflows
name: (template) Elemental E2E tests with Rancher Manager

on:
  workflow_call:
    # Variables to set when calling this reusable workflow
    secrets:
      credentials:
        description: Credentials to use to connect
        required: true
      pat_token:
        # A token is needed to be able to add runner on the repo, maybe this can be changed later
        # This token is linked to a personal account
        # So in case of token issue you have to check (no specific order and for example):
        # - the expiration date
        # - if the account associated still exists
        # - if the person still has access to the repo
        description: PAT token used to add runner
        required: true
      slack_webhook_url:
        description: WebHook URL to use for Slack
        required: true
    inputs:
      ca_type:
        description: CA type to use (selfsigned or private)
        default: selfsigned
        type: string
      cert-manager_version:
        description: Version of cert-manager to use
        type: string
      cluster_name:
        description: Name of the provisioned cluster
        required: true
        type: string
      cluster_type:
        description: Type of the cluster
        type: string
      cypress_tags:
        description: Tags to filter tests we want to run
        default: main
        type: string
      destroy_runner:
        description: Destroy the auto-generated self-hosted runner
        default: true
        type: boolean
      elemental_support:
        description: URL of the elemental support binary
        default: https://github.com/rancher/elemental-operator/releases/download/v1.1.4/elemental-support_1.1.4_linux_amd64
        type: string
      elemental_ui_version:
        description: Version of the elemental ui which will be installed
        default: latest
        type: string
      iso_to_test:
        description: ISO to test (default built one is empty)
        type: string
      k3s_flags:
        description: Argument to configure INSTALL_K3S_EXEC env variable 
        type: string
      k8s_version_to_provision:
        description: Name and version of installed K8s distribution
        required: true
        type: string
      node_number:
        description: Number of nodes to deploy on the provisioned cluster
        default: 5
        type: string
      proxy:
        description: Deploy a proxy
        type: string
      rancher_channel:
        description: Rancher Manager channel to use for installation (alpha/latest/stable)
        default: stable
        type: string
      rancher_log_collector:
        description: URL of the Rancher log collector script
        default: https://raw.githubusercontent.com/rancherlabs/support-tools/master/collection/rancher/v2.x/logs-collector/rancher2_logs_collector.sh
        type: string
      rancher_version:
        description: Rancher Manager version to use for installation (fixed version or latest)
        default: latest
        type: string
      runner_template:
        description: Runner template to use
        default: elemental-e2e-ci-runner-spot-x86-64-template-n2-standard-16-v2
        type: string
      sequential:
        description: Defines if bootstrapping is done sequentially (true) or in parallel (false)
        default: false
        type: string
      start_condition:
        description: Start condition of the runner
        default: success
        type: string
      test_type:
        description: Type of test to run (cli or ui)
        default: cli
        type: string
      ui_account:
        description: Account used to test RBAC role in UI
        required: false
        type: string
      upgrade_channel_list:
        description: URL to version channel list for Elemental OS upgrade
        type: string
      upgrade_image:
        description: Image to use for the Elemental OS upgrade
        type: string
      upgrade_operator:
        description: URL to elemental-operator version to upgrade to
        type: string
      upgrade_os_channel:
        description: Channel to use for the Elemental OS upgrade
        type: string
      upgrade_type:
        description: Type of upgrade to use for the Elemental OS upgrade
        type: string
      workflow_download:
        description: build-ci workflow to use for artifacts
        default: build-ci.yaml
        type: string
      zone:
        description: GCP zone to host the runner
        default: us-central1-a
        type: string

jobs:
  create-runner:
    if: inputs.start_condition == 'success'
    runs-on: ubuntu-latest
    outputs:
      uuid: ${{ steps.generator.outputs.uuid }}
      runner: ${{ steps.generator.outputs.runner }}
    steps:
      # actions/checkout MUST come before auth
      - name: Checkout
        uses: actions/checkout@v3
      - name: Generate UUID and Runner hostname
        id: generator
        run: |
          UUID=$(uuidgen)
          echo "uuid=${UUID}" >> ${GITHUB_OUTPUT}
          echo "runner=elemental-ci-${UUID}" >> ${GITHUB_OUTPUT}
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.credentials }}
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v1
      - name: Create runner
        run: |
          gcloud compute instances create ${{ steps.generator.outputs.runner }} \
            --source-instance-template ${{ inputs.runner_template }} \
            --zone ${{ inputs.zone }}
      - name: Create PAT token secret
        run: |
          echo -n ${{ secrets.pat_token }} \
            | gcloud secrets create PAT_TOKEN_${{ steps.generator.outputs.uuid }} --data-file=-
  e2e:
    needs: create-runner
    runs-on: ${{ needs.create-runner.outputs.uuid }}
    env:
      TIMEOUT_SCALE: 3
      ARCH: amd64
      CERT-MANAGER_VERSION: ${{ inputs.cert-manager_version }}
      CLUSTER_NAME: ${{ inputs.cluster_name }}
      CLUSTER_NS: fleet-default
      CLUSTER_TYPE: ${{ inputs.cluster_type }}
      # For K3s installation used to host Rancher Manager
      INSTALL_K3S_EXEC: ${{ inputs.k3s_flags }}
      INSTALL_K3S_VERSION: v1.24.7+k3s1
      INSTALL_K3S_SKIP_ENABLE: true
      K3S_KUBECONFIG_MODE: 0644
      # For Rancher Manager
      RANCHER_CHANNEL: ${{ inputs.rancher_channel }}
      RANCHER_VERSION: ${{ inputs.rancher_version }}
      UPGRADE_OPERATOR: ${{ inputs.upgrade_operator }}
      # For K8s cluster to provision with Rancher Manager
      K8S_VERSION_TO_PROVISION: ${{ inputs.k8s_version_to_provision }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Install Go
        uses: actions/setup-go@v3
        with:
          go-version: '~1.18'
      - name: Cache ISO
        # NOTE: download the *default* ISO, not the one passed as a parameter
        if: inputs.iso_to_test == ''
        uses: actions/cache@v3
        env:
          cache-name: cache-artifacts
        with:
          path: build/*
          key: build-ci-${{ github.event.pull_request.head.sha || github.sha }}
          # Alternate key, mainly useful for UI test
          restore-keys: |
            build-ci-
      - name: Download specified ISO
        if: inputs.iso_to_test != ''
        env:
          ISO_TO_TEST: ${{ inputs.iso_to_test }}
          TAG: from-obs
        run: |
          mkdir -p build
          wget -v -L -c ${ISO_TO_TEST} -O build/elemental-${TAG}.iso
      - name: Extract iPXE artifacts from ISO
        run: |
          # Extract TAG
          ISO=$(ls build/elemental-*.iso 2>/dev/null)
          TAG=${ISO#*-}
          export TAG=${TAG%.iso}
          # Extract iPXE artifacts
          make extract_kernel_init_squash
          make ipxe
          mv -f build/* .
          # Looks a little bit weird but we have to keep the ISO in build!
          mv -f elemental-*.iso build/
      - name: Deploy Proxy
        id: proxy
        if: inputs.proxy == 'elemental' || inputs.proxy == 'rancher'
        run: docker run -d --name squid_proxy -v $(pwd)/tests/assets/squid.conf:/etc/squid/squid.conf -p 3128:3128 wernight/squid
      - name: Install Rancher
        id: installation
        env:
          CA_TYPE: ${{ inputs.ca_type }}
          PROXY: ${{ inputs.proxy }}
          TEST_TYPE: ${{ inputs.test_type }}
        run: |
          export MY_HOSTNAME=$(hostname -f)
          echo "MY_HOSTNAME=$MY_HOSTNAME" >> $GITHUB_OUTPUT
          cd tests && HOSTNAME=$(hostname -f) make e2e-install-rancher
      - name: Cypress tests - Basics
        # Basics means tests without an extra elemental node needed
        if: inputs.test_type == 'ui'
        env:
          BROWSER: chrome
          CYPRESS_DOCKER: 'cypress/included:10.9.0'
          CYPRESS_TAGS: ${{ inputs.cypress_tags }}
          ELEMENTAL_UI_VERSION: ${{ inputs.elemental_ui_version }}
          RANCHER_PASSWORD: rancherpassword
          RANCHER_URL: https://${{ steps.installation.outputs.MY_HOSTNAME }}/dashboard
          RANCHER_USER: admin
          SPEC: |
            cypress/e2e/unit_tests/first_connection.spec.ts
            cypress/e2e/unit_tests/elemental_plugin.spec.ts
            cypress/e2e/unit_tests/user.spec.ts
            cypress/e2e/unit_tests/menu.spec.ts
            cypress/e2e/unit_tests/machine_registration.spec.ts
            cypress/e2e/unit_tests/advanced_filtering.spec.ts
          UI_ACCOUNT: ${{ inputs.ui_account }}
        run: cd tests && make start-cypress-tests
      - name: Upload Cypress screenshots (Basics)
        if: failure() && inputs.test_type == 'ui'
        uses: actions/upload-artifact@v3
        with:
          name: cypress-screenshots-basics-${{ inputs.cluster_name }}
          path: tests/cypress/screenshots
          retention-days: 7
          if-no-files-found: ignore
      - name: Upload Cypress videos (Basics)
        # Test run video is always captured, so this action uses "always()" condition
        if: always() && inputs.test_type == 'ui'
        uses: actions/upload-artifact@v3
        with:
          name: cypress-videos-basics-${{ inputs.cluster_name }}
          path: tests/cypress/videos
          retention-days: 7
      - name: Deploy a node to join Rancher manager
        if: inputs.test_type == 'ui'
        env:
          VM_INDEX: 1
          HOST_MEMORY_RESERVED: 50331648
        run: |
          cd tests && (
            # Removing 'downloads' is needed to avoid this error during 'make':
            # 'pattern all: open .../elemental/tests/cypress/downloads: permission denied'
            sudo rm -rf cypress/downloads

            make e2e-ui-rancher
          )
      - name: Cypress tests - Advanced
        # Advanced means tests which needs an extra elemental node (provisioned with libvirt)
        if: inputs.test_type == 'ui'
        env:
          BROWSER: firefox
          CYPRESS_DOCKER: 'cypress/included:10.9.0'
          CYPRESS_TAGS: ${{ inputs.cypress_tags }}
          ELEMENTAL_UI_VERSION: ${{ inputs.elemental_ui_version }}
          PROXY: ${{ inputs.proxy }}
          RANCHER_PASSWORD: rancherpassword
          RANCHER_URL: https://${{ steps.installation.outputs.MY_HOSTNAME }}/dashboard
          RANCHER_USER: admin
          SPEC: |
            cypress/e2e/unit_tests/machine_selector.spec.ts
            cypress/e2e/unit_tests/machine_inventory.spec.ts
            cypress/e2e/unit_tests/deploy_app.spec.ts
            cypress/e2e/unit_tests/upgrade.spec.ts
          UI_ACCOUNT: ${{ inputs.ui_account }}
          UPGRADE_CHANNEL_LIST: ${{ inputs.upgrade_channel_list }}
          UPGRADE_IMAGE: ${{ inputs.upgrade_image }}

        run: |
          export OPERATOR_VERSION=$(kubectl get pods \
                                      -n cattle-elemental-system \
                                      -l app=elemental-operator \
                                      -o jsonpath={.items[*].status.containerStatuses[*].image} \
                                    | awk -F ':' '{print substr($2,0,3)}')

          cd tests && make start-cypress-tests
      - name: Upload Cypress screenshots (Advanced)
        if: failure() && inputs.test_type == 'ui'
        uses: actions/upload-artifact@v3
        with:
          name: cypress-screenshots-advanced-${{ inputs.cluster_name }}
          path: tests/cypress/screenshots
          retention-days: 7
          if-no-files-found: ignore
      - name: Upload Cypress videos (Advanced)
        # Test run video is always captured, so this action uses "always()" condition
        if: always() && inputs.test_type == 'ui'
        uses: actions/upload-artifact@v3
        with:
          name: cypress-videos-advanced-${{ inputs.cluster_name }}
          path: tests/cypress/videos
          retention-days: 7
      - name: Configure Rancher & Libvirt
        if: inputs.test_type == 'cli'
        run: cd tests && make e2e-configure-rancher
      - name: Bootstrap node 1, 2 and 3 (with iPXE) in pool "master" (use Emulated TPM if possible)
        if: inputs.test_type == 'cli'
        env:
          EMULATE_TPM: true
          POOL: master
          VM_START: 1
          VM_END: 3
        run: |
          OPERATOR_VERSION=$(kubectl get pods \
                               -n cattle-elemental-system \
                               -l app=elemental-operator \
                               -o jsonpath={.items[*].status.containerStatuses[*].image} \
                             | awk -F ':' '{print substr($2,0,3)}')

          # If elemental-operator is a v1.0.x we should disable EMULATE_TPM
          [[ "${OPERATOR_VERSION}" == "1.0" ]] && unset EMULATE_TPM

          # Disable EMULATE_TPM in case of upgrade test
          # This is because we don't know the version in advance, so easier to not use it
          if ${{ inputs.upgrade_image != '' }}      || \
             ${{ inputs.upgrade_os_channel != '' }} || \
             ${{ contains(inputs.iso_to_test, '/Stable:/') }}; then
            unset EMULATE_TPM
          fi

          if ${{ inputs.sequential == 'true' }}; then
            # Force node bootstrapping in sequential instead of parallel
            cd tests
            for ((i = VM_START ; i <= VM_END ; i++)); do
              VM_INDEX=${i} make e2e-bootstrap-node
            done
          else
            cd tests && VM_INDEX=${VM_START} VM_NUMBERS=${VM_END} make e2e-bootstrap-node
          fi
      - name: Upgrade node 1 to specified OS version with osImage
        if: inputs.test_type == 'cli' && inputs.upgrade_image != ''
        env:
          UPGRADE_IMAGE: ${{ inputs.upgrade_image }}
          UPGRADE_TYPE: osImage
          VM_INDEX: 1
        run: cd tests && make e2e-upgrade-node
      - name: Upgrade other nodes to specified OS version with managedOSVersionName
        if: inputs.test_type == 'cli' && inputs.upgrade_os_channel != ''
        env:
          UPGRADE_CHANNEL_LIST: ${{ inputs.upgrade_channel_list }}
          UPGRADE_OS_CHANNEL: ${{ inputs.upgrade_os_channel }}
          UPGRADE_TYPE: managedOSVersionName
          VM_INDEX: 2
          VM_NUMBERS: 3
        run: cd tests && make e2e-upgrade-node
      - name: Bootstrap additional nodes (with ISO) in pool "worker" (total of ${{ inputs.node_number }})
        if: inputs.test_type == 'cli' && inputs.node_number > 3
        env:
          ISO_BOOT: true
          POOL: worker
          VM_START: 4
          VM_END: ${{ inputs.node_number }}
        run: |
          if ${{ inputs.sequential == 'true' }}; then
            # Force node bootstrapping in sequential instead of parallel
            cd tests
            for ((i = VM_START ; i <= VM_END ; i++)); do
              VM_INDEX=${i} make e2e-bootstrap-node
            done
          else
            cd tests && VM_INDEX=${VM_START} VM_NUMBERS=${VM_END} make e2e-bootstrap-node
          fi
      - name: List installed nodes
        if: inputs.test_type == 'cli'
        run: sudo virsh list
      - name: Store logs
        if: always()
        env:
          ELEMENTAL_SUPPORT: ${{ inputs.elemental_support }}
          PROXY: ${{ inputs.proxy }}
          RANCHER_LOG_COLLECTOR: ${{ inputs.rancher_log_collector }}
        run: |
          cd tests && (
            # Removing 'downloads' is needed to avoid this error during 'make':
            # 'pattern all: open .../elemental/tests/cypress/downloads: permission denied'
            sudo rm -rf cypress/downloads

            make e2e-get-logs
          )
      - name: Upload cluster logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: support-logs
          path: tests/**/logs/*
          if-no-files-found: ignore
      - name: Add summary
        if: always()
        run: |
          # Extract Rancher Manager version
          RM_VERSION=$(kubectl get pod \
                         --namespace cattle-system \
                         -l app=rancher \
                         -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)
          # Extract elemental-operator version
          OPERATOR_VERSION=$(kubectl get pod \
                             --namespace cattle-elemental-system \
                             -l app=elemental-operator \
                             -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)
          # Add summary
          echo "## General informations" >> $GITHUB_STEP_SUMMARY
          if ${{ inputs.test_type == 'cli' }}; then
            echo "Number of nodes in the cluster: ${{ inputs.node_number }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "Type of certificate for Rancher Manager: ${{ inputs.ca_type }}"  >> $GITHUB_STEP_SUMMARY
          echo "## Versions used" >> $GITHUB_STEP_SUMMARY
          echo "Rancher Manager Channel: ${{ env.RANCHER_CHANNEL }}/${{ env.RANCHER_VERSION }}" >> $GITHUB_STEP_SUMMARY
          echo "Rancher Manager Version: ${RM_VERSION}" >> $GITHUB_STEP_SUMMARY
          echo "Elemental Operator Upgrade: ${{ env.UPGRADE_OPERATOR || 'N/A' }}" >> $GITHUB_STEP_SUMMARY
          echo "Elemental Operator Version: ${OPERATOR_VERSION}" >> $GITHUB_STEP_SUMMARY
          echo "Elemental UI Extension Version (if applicable): ${{ inputs.elemental_ui_version }}" >> $GITHUB_STEP_SUMMARY
          echo "K3s on Rancher Manager: ${{ env.INSTALL_K3S_VERSION }}" >> $GITHUB_STEP_SUMMARY
          echo "K3s/RKE2 version deployed on the cluster: ${{ inputs.k8s_version_to_provision }}" >> $GITHUB_STEP_SUMMARY
          # Upgrade details
          if ${{ inputs.upgrade_image != '' }} || ${{ inputs.upgrade_os_channel != '' }}; then
            echo "## Upgrade details" >> $GITHUB_STEP_SUMMARY
            echo "Channel list: ${{ inputs.upgrade_channel_list }}" >> $GITHUB_STEP_SUMMARY
            echo "Channel used: ${{ inputs.upgrade_os_channel }}" >> $GITHUB_STEP_SUMMARY
            echo "Upgrade image: ${{ inputs.upgrade_image }}" >> $GITHUB_STEP_SUMMARY
          fi
      - name: Send failed status to slack
        if: failure() && github.event_name == 'schedule'
        uses: slackapi/slack-github-action@v1.23.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "section",
                    "text": {
                      "type": "mrkdwn",
                      "text": "Workflow build-ci ${{ github.job }}"
                    },
                    "accessory": {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": ":github:",
                         "emoji": true
                        },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.slack_webhook_url }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
  delete-runner:
    if: always() && needs.create-runner.result == 'success' && inputs.destroy_runner == true
    needs: [create-runner, e2e]
    runs-on: ubuntu-latest
    steps:
      # actions/checkout MUST come before auth
      - name: Checkout
        uses: actions/checkout@v3
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.credentials }}
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v1
      - name: Delete PAT token secret
        run: |
          gcloud --quiet secrets delete PAT_TOKEN_${{ needs.create-runner.outputs.uuid }}
      - name: Delete runner
        run: |
          gcloud --quiet compute instances delete ${{ needs.create-runner.outputs.runner }} \
            --delete-disks all \
            --zone ${{ inputs.zone }}
